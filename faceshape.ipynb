{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Python programming\\\\Face Detection\\\\shape_predictor_81_face_landmarks.dat',\n",
       " <http.client.HTTPMessage at 0x24219c03d60>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "shape_predictor_url = \"https://github.com/codeniko/shape_predictor_81_face_landmarks/blob/master/shape_predictor_81_face_landmarks.dat\"\n",
    "shape_predictor_path = \"C:\\\\Python programming\\\\Face Detection\\\\shape_predictor_81_face_landmarks.dat\"\n",
    "\n",
    "urllib.request.urlretrieve(shape_predictor_url, shape_predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "model_path = \"C:\\Python programming\\Face Detection\\githubrepo\\shape_predictor_81_face_landmarks-master\\shape_predictor_81_face_landmarks.dat\"\n",
    "\n",
    "model = dlib.shape_predictor(model_path)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def distance(point1, point2):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def angle(p1, p2, p3):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "    \n",
    "    # Calculate the vectors of the two lines\n",
    "    vector1 = (x1 - x2, y1 - y2)\n",
    "    vector2 = (x3 - x2, y3 - y2)\n",
    "    \n",
    "    # Calculate the dot product and magnitudes of the vectors\n",
    "    dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
    "    magnitude1 = math.sqrt(vector1[0] ** 2 + vector1[1] ** 2)\n",
    "    magnitude2 = math.sqrt(vector2[0] ** 2 + vector2[1] ** 2)\n",
    "    \n",
    "    # Calculate the cosine of the angle between the lines\n",
    "    cosine = dot_product / (magnitude1 * magnitude2)\n",
    "    \n",
    "    # Calculate the angle in radians and convert to degrees\n",
    "    angle_rad = math.acos(cosine)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "\n",
    "def midpoint(point1, point2):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Calculate the midpoint coordinates\n",
    "    midpoint_x = (x1 + x2) / 2\n",
    "    midpoint_y = (y1 + y2) / 2\n",
    "    \n",
    "    # Create an array to store the midpoint coordinates\n",
    "    midpoint = [midpoint_x, midpoint_y]\n",
    "    \n",
    "    return midpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Heart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oblong\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Oblong\n",
      "Error: Failed to load image or image file does not exist.\n",
      "Oval\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Oval\n",
      "Round\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Round\n",
      "Square\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Square\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_pth = \"C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\FaceShape Dataset\\\\training_set\"\n",
    "\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "for shape in os.listdir(data_pth):\n",
    "    print(shape)\n",
    "    shape_pth = os.path.join(data_pth, shape)\n",
    "    print(shape_pth)\n",
    "    for img in os.listdir(shape_pth):\n",
    "        \n",
    "        img_pth = os.path.join(shape_pth, img)\n",
    "\n",
    "        # print(img_pth)\n",
    "\n",
    "        pic = cv2.imread(img_pth)\n",
    "\n",
    "        if pic is None:\n",
    "            print(\"Error: Failed to load image or image file does not exist.\")\n",
    "            continue\n",
    "        else:\n",
    "            # Convert the image to grayscale or perform other operations\n",
    "            pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "\n",
    "        # pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        dets = detector(pic)\n",
    "\n",
    "        # for k, d in enumerate(dets):\n",
    "\n",
    "        for face in dets:\n",
    "            shape = model(pic, face)\n",
    "            coords = face_utils.shape_to_np(shape)   # our coordinates of face landmarks are stored here\n",
    "            # landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n",
    "            \n",
    "        #     for (x, y) in coords:\n",
    "        #         # Process or visualize the landmark coordinates\n",
    "        #         cv2.circle(pic, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "\n",
    "        # cv2.imshow(\"Landmarks\", pic)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        \n",
    "        l2 = coords[2]\n",
    "        l14 = coords[14]\n",
    "        l69 = coords[69]\n",
    "        l75 = coords[75]\n",
    "        l79 = coords[79]\n",
    "        l72 = coords[72]\n",
    "        l8 = coords[8]\n",
    "        l12 = coords[12]\n",
    "        l4 = coords[4]\n",
    "        l6 = coords[6]\n",
    "        l10 = coords[10]\n",
    "        l7 = coords[7]\n",
    "        l9 = coords[9]\n",
    "\n",
    "        d1 = distance(l2, l14)\n",
    "        d2 = distance(l75, l79)\n",
    "        d3 = distance(midpoint(l69, l72), l8)\n",
    "        d4 = distance(l8, l12)\n",
    "        d5 = distance(l4, l12)\n",
    "        d6 = distance(l6, l10)\n",
    "        d7 = distance(l7, l9)\n",
    "\n",
    "\n",
    "        DD = d1 + d2 + d3 + d4 + d5 + d6 + d7\n",
    "\n",
    "        D1 = d1/DD\n",
    "        D2 = d2/DD\n",
    "        D3 = d3/DD\n",
    "        D4 = d4/DD\n",
    "        D5 = d5/DD\n",
    "        D6 = d6/DD\n",
    "        D7 = d7/DD\n",
    "\n",
    "\n",
    "\n",
    "        R1 = D2/D1\n",
    "        R2 = D1/D3\n",
    "        R3 = D2/D3\n",
    "        R4 = D1/D5\n",
    "        R5 = D6/D5\n",
    "        R6 = D4/D6\n",
    "        R7 = D6/D1\n",
    "        R8 = D5/D2\n",
    "        R9 = D4/D5\n",
    "        R10 = D7/D6\n",
    "\n",
    "\n",
    "        A1 = angle(midpoint(l69, l72), l8, l10)\n",
    "        A2 = angle(midpoint(l69, l72), l8, l12)\n",
    "        A3 = angle(l2, l14, l12)\n",
    "\n",
    "\n",
    "        features = []\n",
    "\n",
    "        features.append(R1)\n",
    "        features.append(R2)\n",
    "        features.append(R3)\n",
    "        features.append(R4)\n",
    "        features.append(R7)\n",
    "        features.append(R8)\n",
    "        features.append(R10)\n",
    "        features.append(D1)\n",
    "        features.append(D2)\n",
    "        features.append(D3)\n",
    "        features.append(D5)\n",
    "        features.append(D6)\n",
    "        features.append(A1)\n",
    "        features.append(A2)\n",
    "\n",
    "        features = np.array(features)\n",
    "\n",
    "        if shape == 'Heart':\n",
    "            labels.append(0)\n",
    "        elif shape == 'Oblong':\n",
    "            labels.append(1)\n",
    "        elif shape == 'Oval':\n",
    "            labels.append(2)\n",
    "        elif shape == 'Round':\n",
    "            labels.append(3)\n",
    "        else:\n",
    "            labels.append(4)\n",
    "\n",
    "\n",
    "        faces.append(features)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\df.pickle', 'wb')\n",
    "pickle.dump({'data': faces, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = faces\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = open('C:\\Python programming\\Face Detection\\shapemodel.p', 'wb')\n",
    "pickle.dump({'model' : model, 'labels': labels}, ff)\n",
    "ff.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
