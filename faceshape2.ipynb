{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Python programming\\\\Face Detection\\\\shape_predictor_81_face_landmarks.dat',\n",
       " <http.client.HTTPMessage at 0x13fe6c9a7d0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# shape_predictor_url = \"https://github.com/codeniko/shape_predictor_81_face_landmarks/blob/master/shape_predictor_81_face_landmarks.dat\"\n",
    "shape_predictor_path = \"C:\\\\Python programming\\\\Face Detection\\\\shape_predictor_81_face_landmarks.dat\"\n",
    "\n",
    "urllib.request.urlretrieve(shape_predictor_url, shape_predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "model_path = \"C:\\Python programming\\Face Detection\\githubrepo\\shape_predictor_81_face_landmarks-master\\shape_predictor_81_face_landmarks.dat\"\n",
    "\n",
    "model = dlib.shape_predictor(model_path)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def distance(point1, point2):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def angle(p1, p2, p3):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "    \n",
    "    # Calculate the vectors of the two lines\n",
    "    vector1 = (x1 - x2, y1 - y2)\n",
    "    vector2 = (x3 - x2, y3 - y2)\n",
    "    \n",
    "    # Calculate the dot product and magnitudes of the vectors\n",
    "    dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
    "    magnitude1 = math.sqrt(vector1[0] ** 2 + vector1[1] ** 2)\n",
    "    magnitude2 = math.sqrt(vector2[0] ** 2 + vector2[1] ** 2)\n",
    "    \n",
    "    # Calculate the cosine of the angle between the lines\n",
    "    cosine = dot_product / (magnitude1 * magnitude2)\n",
    "    \n",
    "    # Calculate the angle in radians and convert to degrees\n",
    "    angle_rad = math.acos(cosine)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "\n",
    "def midpoint(point1, point2):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Calculate the midpoint coordinates\n",
    "    midpoint_x = (x1 + x2) / 2\n",
    "    midpoint_y = (y1 + y2) / 2\n",
    "    \n",
    "    # Create an array to store the midpoint coordinates\n",
    "    midpoint = [midpoint_x, midpoint_y]\n",
    "    \n",
    "    return midpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Heart\n",
      "Oblong\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Oblong\n",
      "Error: Failed to load image or image file does not exist.\n",
      "Oval\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Oval\n",
      "Round\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Round\n",
      "Square\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Square\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_pth = \"C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\FaceShape Dataset\\\\training_set\"\n",
    "\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "for shape in os.listdir(data_pth):\n",
    "    print(shape)\n",
    "    k = shape\n",
    "    shape_pth = os.path.join(data_pth, shape)\n",
    "    print(shape_pth)\n",
    "    for img in os.listdir(shape_pth):\n",
    "        \n",
    "        img_pth = os.path.join(shape_pth, img)\n",
    "\n",
    "        # print(img_pth)\n",
    "\n",
    "        pic = cv2.imread(img_pth)\n",
    "\n",
    "        if pic is None:\n",
    "            print(\"Error: Failed to load image or image file does not exist.\")\n",
    "            continue\n",
    "        else:\n",
    "            # Convert the image to grayscale or perform other operations\n",
    "            pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "\n",
    "        # pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        dets = detector(pic)\n",
    "\n",
    "        # for k, d in enumerate(dets):\n",
    "\n",
    "        for face in dets:\n",
    "            shape = model(pic, face)\n",
    "            coords = face_utils.shape_to_np(shape)   # our coordinates of face landmarks are stored here\n",
    "            # landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n",
    "            \n",
    "        #     for (x, y) in coords:\n",
    "        #         # Process or visualize the landmark coordinates\n",
    "        #         cv2.circle(pic, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "\n",
    "        # cv2.imshow(\"Landmarks\", pic)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        \n",
    "        l3 = coords[3]\n",
    "        l15 = coords[15]\n",
    "        l70 = coords[70]\n",
    "        l76 = coords[76]\n",
    "        l80 = coords[80]\n",
    "        l73 = coords[73]\n",
    "        l9 = coords[9]\n",
    "        l13 = coords[13]\n",
    "        l5 = coords[5]\n",
    "        l7 = coords[7]\n",
    "        l11 = coords[11]\n",
    "        l8 = coords[8]\n",
    "        l10 = coords[10]\n",
    "\n",
    "        d1 = distance(l3, l15)\n",
    "        d2 = distance(l76, l80)\n",
    "        d3 = distance(midpoint(l70, l73), l9)\n",
    "        d4 = distance(l9, l13)\n",
    "        d5 = distance(l5, l13)\n",
    "        d6 = distance(l7, l11)\n",
    "        d7 = distance(l8, l10)\n",
    "\n",
    "\n",
    "        DD = d1 + d2 + d3 + d4 + d5 + d6 + d7\n",
    "\n",
    "        D1 = d1/DD\n",
    "        D2 = d2/DD\n",
    "        D3 = d3/DD\n",
    "        D4 = d4/DD\n",
    "        D5 = d5/DD\n",
    "        D6 = d6/DD\n",
    "        D7 = d7/DD\n",
    "\n",
    "\n",
    "\n",
    "        R1 = D2/D1\n",
    "        R2 = D1/D3\n",
    "        R3 = D2/D3\n",
    "        R4 = D1/D5\n",
    "        R5 = D6/D5\n",
    "        R6 = D4/D6\n",
    "        R7 = D6/D1\n",
    "        R8 = D5/D2\n",
    "        R9 = D4/D5\n",
    "        R10 = D7/D6\n",
    "\n",
    "\n",
    "        A1 = angle(midpoint(l70, l73), l9, l11)\n",
    "        A2 = angle(midpoint(l70, l73), l9, l13)\n",
    "        A3 = angle(l3, l15, l13)\n",
    "\n",
    "\n",
    "        features = []\n",
    "\n",
    "        features.append(R1)\n",
    "        features.append(R2)\n",
    "        features.append(R3)\n",
    "        features.append(R4)\n",
    "        features.append(R7)\n",
    "        features.append(R8)\n",
    "        features.append(R10)\n",
    "        features.append(D1)\n",
    "        features.append(D2)\n",
    "        features.append(D3)\n",
    "        features.append(D5)\n",
    "        features.append(D6)\n",
    "        features.append(A1)\n",
    "        features.append(A2)\n",
    "\n",
    "        features = np.array(features)\n",
    "\n",
    "        # print(k)\n",
    "\n",
    "        if k == \"Heart\":\n",
    "            labels.append(0)\n",
    "        elif k == \"Oblong\":\n",
    "            labels.append(1)\n",
    "        elif k == \"Oval\":\n",
    "            labels.append(2)\n",
    "        elif k == \"Round\":\n",
    "            labels.append(3)\n",
    "        elif k == \"Square\":\n",
    "            labels.append(4)\n",
    "        else: \n",
    "            print('ERROR')\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "        faces.append(features)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\df.pickle', 'wb')\n",
    "pickle.dump({'data': faces, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.61131643  0.80599745  0.49271948 ...  0.1011932  54.40786326\n",
      "  42.89573285]\n",
      " [ 0.62248638  0.83821137  0.52177516 ...  0.09196814 43.88695099\n",
      "  36.63007653]\n",
      " [ 0.5671755   0.77425265  0.43913713 ...  0.10038232 49.85828189\n",
      "  39.80893331]\n",
      " ...\n",
      " [ 0.5854374   0.85204606  0.49881963 ...  0.10067417 57.70665743\n",
      "  45.10649761]\n",
      " [ 0.57836419  0.85749548  0.49594468 ...  0.09983551 63.91990756\n",
      "  48.66478886]\n",
      " [ 0.56418698  0.84092246  0.47443751 ...  0.10977618 70.85000837\n",
      "  54.35928992]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = np.array(faces)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# X_train = np.reshape(X_train, (3999, 14))\n",
    "\n",
    "# X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "\n",
    "# y_train.reshape(3999, 1)\n",
    "\n",
    "# y_train = np.reshape(y_train, (3999, 1))\n",
    "\n",
    "X_train = np.reshape(X_train, (3999, 14))\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# import keras \n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_units = 64\n",
    "# timesteps = 3999\n",
    "# input_dim = 14\n",
    "# num_classes = 5\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units=hidden_units, input_shape=(1, 14)))\n",
    "# model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = open('C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\shapemodel.p', 'wb')\n",
    "pickle.dump({'model' : model, 'labels': labels}, ff)\n",
    "ff.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
