{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "model_path = \"C:\\Python programming\\Face Detection\\githubrepo\\shape_predictor_81_face_landmarks-master\\shape_predictor_81_face_landmarks.dat\"\n",
    "\n",
    "model = dlib.shape_predictor(model_path)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def distance(point1, point2):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def angle(p1, p2, p3):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "    \n",
    "    # Calculate the vectors of the two lines\n",
    "    vector1 = (x1 - x2, y1 - y2)\n",
    "    vector2 = (x3 - x2, y3 - y2)\n",
    "    \n",
    "    # Calculate the dot product and magnitudes of the vectors\n",
    "    dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
    "    magnitude1 = math.sqrt(vector1[0] ** 2 + vector1[1] ** 2)\n",
    "    magnitude2 = math.sqrt(vector2[0] ** 2 + vector2[1] ** 2)\n",
    "    \n",
    "    # Calculate the cosine of the angle between the lines\n",
    "    cosine = dot_product / (magnitude1 * magnitude2)\n",
    "    \n",
    "    # Calculate the angle in radians and convert to degrees\n",
    "    angle_rad = math.acos(cosine)\n",
    "    angle_deg = math.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "\n",
    "def midpoint(point1, point2):\n",
    "    # Unpack the coordinates from the input arrays\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Calculate the midpoint coordinates\n",
    "    midpoint_x = (x1 + x2) / 2\n",
    "    midpoint_y = (y1 + y2) / 2\n",
    "    \n",
    "    # Create an array to store the midpoint coordinates\n",
    "    midpoint = [midpoint_x, midpoint_y]\n",
    "    \n",
    "    return midpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Heart\n",
      "Oblong\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Oblong\n",
      "Error: Failed to load image or image file does not exist.\n",
      "Oval\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Oval\n",
      "Round\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Round\n",
      "Square\n",
      "C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\training_set\\Square\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_pth = \"C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\FaceShape Dataset\\\\training_set\"\n",
    "\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "for shape in os.listdir(data_pth):\n",
    "    print(shape)\n",
    "    k = shape\n",
    "    shape_pth = os.path.join(data_pth, shape)\n",
    "    print(shape_pth)\n",
    "    for img in os.listdir(shape_pth):\n",
    "        \n",
    "        img_pth = os.path.join(shape_pth, img)\n",
    "\n",
    "        # print(img_pth)\n",
    "\n",
    "        pic = cv2.imread(img_pth)\n",
    "\n",
    "        if pic is None:\n",
    "            print(\"Error: Failed to load image or image file does not exist.\")\n",
    "            continue\n",
    "        else:\n",
    "            # Convert the image to grayscale or perform other operations\n",
    "            pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "\n",
    "        # pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        dets = detector(pic)\n",
    "\n",
    "        # for k, d in enumerate(dets):\n",
    "\n",
    "        for face in dets:\n",
    "            shape = model(pic, face)\n",
    "            coords = face_utils.shape_to_np(shape)   # our coordinates of face landmarks are stored here\n",
    "            # landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n",
    "            \n",
    "        #     for (x, y) in coords:\n",
    "        #         # Process or visualize the landmark coordinates\n",
    "        #         cv2.circle(pic, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "\n",
    "        # cv2.imshow(\"Landmarks\", pic)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        \n",
    "        l3 = coords[3]\n",
    "        l15 = coords[15]\n",
    "        l70 = coords[70]\n",
    "        l76 = coords[76]\n",
    "        l80 = coords[80]\n",
    "        l73 = coords[73]\n",
    "        l9 = coords[9]\n",
    "        l13 = coords[13]\n",
    "        l5 = coords[5]\n",
    "        l7 = coords[7]\n",
    "        l11 = coords[11]\n",
    "        l8 = coords[8]\n",
    "        l10 = coords[10]\n",
    "\n",
    "        d1 = distance(l3, l15)\n",
    "        d2 = distance(l76, l80)\n",
    "        d3 = distance(midpoint(l70, l73), l9)\n",
    "        d4 = distance(l9, l13)\n",
    "        d5 = distance(l5, l13)\n",
    "        d6 = distance(l7, l11)\n",
    "        d7 = distance(l8, l10)\n",
    "\n",
    "\n",
    "        DD = d1 + d2 + d3 + d4 + d5 + d6 + d7\n",
    "\n",
    "        D1 = d1/DD\n",
    "        D2 = d2/DD\n",
    "        D3 = d3/DD\n",
    "        D4 = d4/DD\n",
    "        D5 = d5/DD\n",
    "        D6 = d6/DD\n",
    "        D7 = d7/DD\n",
    "\n",
    "\n",
    "\n",
    "        R1 = D2/D1\n",
    "        R2 = D1/D3\n",
    "        R3 = D2/D3\n",
    "        R4 = D1/D5\n",
    "        R5 = D6/D5\n",
    "        R6 = D4/D6\n",
    "        R7 = D6/D1\n",
    "        R8 = D5/D2\n",
    "        R9 = D4/D5\n",
    "        R10 = D7/D6\n",
    "\n",
    "\n",
    "        A1 = angle(midpoint(l70, l73), l9, l11)\n",
    "        A2 = angle(midpoint(l70, l73), l9, l13)\n",
    "        A3 = angle(l3, l15, l13)\n",
    "\n",
    "\n",
    "        features = []\n",
    "\n",
    "        features.append(R1)\n",
    "        features.append(R2)\n",
    "        features.append(R3)\n",
    "        features.append(R4)\n",
    "        features.append(R7)\n",
    "        features.append(R8)\n",
    "        features.append(R10)\n",
    "        features.append(D1)\n",
    "        features.append(D2)\n",
    "        features.append(D3)\n",
    "        features.append(D5)\n",
    "        features.append(D6)\n",
    "        features.append(A1)\n",
    "        features.append(A2)\n",
    "\n",
    "        features = np.array(features)\n",
    "\n",
    "        # print(k)\n",
    "\n",
    "        if k == \"Heart\":\n",
    "            labels.append(0)\n",
    "        elif k == \"Oblong\":\n",
    "            labels.append(1)\n",
    "        elif k == \"Oval\":\n",
    "            labels.append(2)\n",
    "        elif k == \"Round\":\n",
    "            labels.append(3)\n",
    "        elif k == \"Square\":\n",
    "            labels.append(4)\n",
    "        else: \n",
    "            print('ERROR')\n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "        faces.append(features)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\df.pickle', 'wb')\n",
    "pickle.dump({'data': faces, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df = pickle.load(open('C:\\Python programming\\Face Detection\\Face Shape Dataset\\df.pickle', 'rb'))\n",
    "\n",
    "faces = df['data']\n",
    "labels = df['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(faces)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "# X_train = np.reshape(X_train, (3999, 14))\n",
    "\n",
    "X_train = np.reshape(X_train, (3999, 14, 1))\n",
    "\n",
    "# y_train.reshape(3999, 1)\n",
    "\n",
    "# y_train = np.reshape(y_train, (3999, 1))\n",
    "\n",
    "X_train = np.reshape(X_train, (3999, 14))\n",
    "\n",
    "# print(X_train)\n",
    "\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Reorder the samples using the shuffled indices\n",
    "shuffled_X = X_train[indices]\n",
    "shuffled_y = y_train[indices]\n",
    "# print(X_train)\n",
    "# print(shuffled_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# import keras \n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# hidden_units = 64\n",
    "# timesteps = 3999\n",
    "# input_dim = 14\n",
    "# num_classes = 5\n",
    "\n",
    "# model = Sequential()\n",
    "# # model.add(LSTM(units=hidden_units, input_shape=(1, 14)))\n",
    "\n",
    "# model.add(LSTM(units=32, activation='relu', input_shape=(14, 1)))\n",
    "# model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# # Assuming y_train is a 1D array of class labels\n",
    "\n",
    "# # Perform one-hot encoding on the target variable\n",
    "# y_train = to_categorical(y_train, num_classes=5)\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 13ms/step - loss: 7.3161 - accuracy: 0.1993\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7544 - accuracy: 0.1940\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1990 - accuracy: 0.1973\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.2662 - accuracy: 0.2038\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8838 - accuracy: 0.1960\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7742 - accuracy: 0.1983\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7173 - accuracy: 0.2156\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6624 - accuracy: 0.1993\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6293 - accuracy: 0.2221\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6056 - accuracy: 0.2258\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6016 - accuracy: 0.2018\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5871 - accuracy: 0.2366\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5851 - accuracy: 0.2428\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5827 - accuracy: 0.2183\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5801 - accuracy: 0.2466\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5784 - accuracy: 0.2421\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5786 - accuracy: 0.2626\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5767 - accuracy: 0.2696\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5761 - accuracy: 0.2481\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5738 - accuracy: 0.2608\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5734 - accuracy: 0.2581\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5729 - accuracy: 0.2808\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5719 - accuracy: 0.2811\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5714 - accuracy: 0.2606\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5697 - accuracy: 0.2823\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5686 - accuracy: 0.2633\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5677 - accuracy: 0.2798\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5669 - accuracy: 0.2791\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5660 - accuracy: 0.3141\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5642 - accuracy: 0.2616\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5639 - accuracy: 0.2896\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5616 - accuracy: 0.3076\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5614 - accuracy: 0.2858\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5583 - accuracy: 0.2748\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5564 - accuracy: 0.3113\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5542 - accuracy: 0.2776\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5496 - accuracy: 0.3286\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5370 - accuracy: 0.3138\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5326 - accuracy: 0.3303\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5244 - accuracy: 0.3211\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5106 - accuracy: 0.3308\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4885 - accuracy: 0.3983\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.4553 - accuracy: 0.4376\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4100 - accuracy: 0.4569\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3613 - accuracy: 0.4534\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3240 - accuracy: 0.4474\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2979 - accuracy: 0.4646\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2814 - accuracy: 0.4484\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2669 - accuracy: 0.4721\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2532 - accuracy: 0.4644\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2540 - accuracy: 0.4724\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2533 - accuracy: 0.4616\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.2431 - accuracy: 0.4684\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2352 - accuracy: 0.4831\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2289 - accuracy: 0.4776\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2265 - accuracy: 0.4774\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2237 - accuracy: 0.4811\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2258 - accuracy: 0.4769\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2179 - accuracy: 0.4861\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2180 - accuracy: 0.4826\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2202 - accuracy: 0.4816\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2226 - accuracy: 0.4784\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2173 - accuracy: 0.4814\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.2111 - accuracy: 0.4976\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2068 - accuracy: 0.4891\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2095 - accuracy: 0.4816\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2126 - accuracy: 0.4824\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2149 - accuracy: 0.4846\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2044 - accuracy: 0.4936\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2026 - accuracy: 0.4914\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1979 - accuracy: 0.4954\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1953 - accuracy: 0.4974\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1943 - accuracy: 0.5006\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2035 - accuracy: 0.4904\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2120 - accuracy: 0.4801\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2069 - accuracy: 0.4916\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1961 - accuracy: 0.4946\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1953 - accuracy: 0.4956\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1985 - accuracy: 0.4934\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1897 - accuracy: 0.5001\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1914 - accuracy: 0.4924\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1955 - accuracy: 0.4986\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1973 - accuracy: 0.4936\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1888 - accuracy: 0.4999\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1819 - accuracy: 0.5031\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1837 - accuracy: 0.5016\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1842 - accuracy: 0.5049\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1941 - accuracy: 0.4964\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1888 - accuracy: 0.4964\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1820 - accuracy: 0.5009\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1782 - accuracy: 0.5079\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1735 - accuracy: 0.5099\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1777 - accuracy: 0.5121\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1794 - accuracy: 0.5036\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1802 - accuracy: 0.5039\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1740 - accuracy: 0.5079\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2038 - accuracy: 0.4851\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1932 - accuracy: 0.4919\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1902 - accuracy: 0.4999\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1739 - accuracy: 0.5134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2569b03d390>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import SimpleRNN, Dense\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# # Convert y_train to one-hot encoded labels\n",
    "# num_classes = 5\n",
    "# y_train_encoded = to_categorical(shuffled_y, num_classes=num_classes)\n",
    "\n",
    "# # Define the model\n",
    "# smodel = Sequential()\n",
    "# smodel.add(SimpleRNN(units=64, activation='relu', input_shape=(14,1)))\n",
    "# smodel.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# # Compile the model\n",
    "# smodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# smodel.fit(shuffled_X, y_train_encoded, batch_size=800, epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# smodel = RandomForestClassifier()\n",
    "\n",
    "# smodel.fit(shuffled_X, shuffled_y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting model (Most Accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "smodel = GradientBoostingClassifier()\n",
    "\n",
    "smodel.fit(shuffled_X, shuffled_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.501"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "testdf = pickle.load(open('C:\\\\Python programming\\\\Face Detection\\\\Face Shape Dataset\\\\testdf.pickle', 'rb'))\n",
    "\n",
    "faces_t = testdf['data']\n",
    "labels_t = testdf['labels']\n",
    "\n",
    "X_test = np.array(faces_t)\n",
    "y_test = np.array(labels_t)\n",
    "\n",
    "predictions = smodel.predict(X_test)\n",
    "# predictions = np.argmax(predictions, axis = 1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "ff = open('C:\\Python programming\\Face Detection\\Face Shape Dataset\\FaceShape Dataset\\shapemodel.p', 'wb')\n",
    "pickle.dump({'model' : smodel, 'labels': labels}, ff)\n",
    "ff.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
